{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef11257",
   "metadata": {},
   "source": [
    "Perform Image Augmentation and build custom CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision matplotlib tqdm torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b5a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534c4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e8c304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8e78b0cbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6a5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations and normalizations\n",
    "\n",
    "if augmentation == False:\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "else:\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768fff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train = '../final_dataset/train'\n",
    "data_dir_test = '../final_dataset/test'\n",
    "\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(root=data_dir_train, transform=data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(root=data_dir_test, transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=16, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f7861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}...\".format(epoch))\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = corrects.double() / len(image_datasets[phase])\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54970fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Add the third set of convolutional, activation, and pooling layers\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # using adaptive pooling layer because image sizes are not fixed. \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1)) \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = self.pool3(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)  # You can choose to include or exclude dropout based on your requirements\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab114d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Hyperparamters\n",
    "\n",
    "num_epochs = 10\n",
    "cnn_model = SimpleCNN()\n",
    "cnn_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model.to(device)\n",
    "\n",
    "train_model(cnn_model, cnn_optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet Model\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # Load the pre-trained ResNet-32 model\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify the final fully connected layer to match the number of classes in your problem\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "# Create an instance of the ResNet32 model\n",
    "resnet_model = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c49290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet Hyperparameters\n",
    "\n",
    "resnet_num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_optimizer = optim.Adam([\n",
    "    {'params': resnet_model.resnet18.conv1.parameters(), 'lr': 0.0001},\n",
    "    {'params': resnet_model.resnet18.layer1.parameters(), 'lr': 0.0001},\n",
    "    {'params': resnet_model.resnet18.layer2.parameters(), 'lr': 0.0001},\n",
    "    {'params': resnet_model.resnet18.layer3.parameters(), 'lr': 0.0001},\n",
    "    {'params': resnet_model.resnet18.layer4.parameters(), 'lr': 0.0001},\n",
    "    {'params': resnet_model.resnet18.fc.parameters(), 'lr': 0.001},\n",
    "], lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model.to(device)\n",
    "\n",
    "train_model(resnet_model, resnet_optimizer, resnet_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09563f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vansh/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/vansh/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /Users/vansh/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n",
      "100%|██████████████████████████████████████| 8.79M/8.79M [00:00<00:00, 22.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4612 Acc: 0.7869\n",
      "val Loss: 0.2782 Acc: 0.8900\n",
      "Epoch 1...\n",
      "train Loss: 0.3868 Acc: 0.8227\n",
      "val Loss: 0.1746 Acc: 0.9397\n",
      "Epoch 2...\n",
      "train Loss: 0.3847 Acc: 0.8306\n",
      "val Loss: 0.1975 Acc: 0.9131\n",
      "Epoch 3...\n",
      "train Loss: 0.3712 Acc: 0.8455\n",
      "val Loss: 0.1928 Acc: 0.9222\n",
      "Epoch 4...\n",
      "train Loss: 0.3466 Acc: 0.8482\n",
      "val Loss: 0.1634 Acc: 0.9439\n",
      "Epoch 5...\n",
      "train Loss: 0.3500 Acc: 0.8424\n",
      "val Loss: 0.1941 Acc: 0.9432\n",
      "Epoch 6...\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Net Model\n",
    "\n",
    "shufflenet_model = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "shufflenet_model.fc = nn.Linear(1024, 2)\n",
    "\n",
    "shufflenet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shufflenet_optimizer = optim.Adam(shufflenet_model.parameters(), lr=0.001)\n",
    "shufflenet_num_epochs = 10\n",
    "\n",
    "train_model(shufflenet_model, shufflenet_optimizer, shufflenet_num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66a1996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0fadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
